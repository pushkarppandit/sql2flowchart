{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "from sqlparse.sql import Token, TokenList\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_query(tokens):\n",
    "#     tokens_flagged = []\n",
    "#     tokens_exp = []\n",
    "#     for t in tokens:\n",
    "#         if isinstance(t,sqlparse.sql.Where):\n",
    "#             for tt in t.tokens:\n",
    "#                 tokens_exp.append(tt)\n",
    "#         else:\n",
    "#             tokens_exp.append(t)\n",
    "            \n",
    "# #     print(tokens_exp)\n",
    "    \n",
    "#     for t in tokens_exp:\n",
    "#         for pattern in ['Token.Text.Whitespace*','Token.Punctuation*']:\n",
    "#             if re.match(pattern,str(t.ttype)):\n",
    "#                 tokens_flagged.append(t)\n",
    "                \n",
    "#     tokens_cleaned = [t for t in tokens_exp if t not in tokens_flagged]\n",
    "#     tokens_cleaned = [t for t in tokens_cleaned if type(t) not in [sqlparse.sql.Comment]]\n",
    "#     return tokens_cleaned\n",
    "\n",
    "def clean_query(tokens):\n",
    "    tokens_exp = []\n",
    "    tokens_cleaned = []\n",
    "    for t in tokens:\n",
    "        if isinstance(t,sqlparse.sql.Where):\n",
    "            for tt in t.tokens:\n",
    "                tokens_exp.append(tt)\n",
    "        else:\n",
    "            tokens_exp.append(t)\n",
    "            \n",
    "#     print(tokens_exp)\n",
    "    \n",
    "    for t in tokens_exp:\n",
    "        append_flag = True\n",
    "        for pattern in ['Token.Text.Whitespace*','Token.Punctuation*']:\n",
    "            if re.match(pattern,str(t.ttype)):\n",
    "                append_flag = False\n",
    "        for t_type in [sqlparse.sql.Comment]:\n",
    "            if type(t)==t_type:\n",
    "                append_flag = False\n",
    "                \n",
    "        if append_flag:\n",
    "            tokens_cleaned.append(t)\n",
    "                \n",
    "#     tokens_cleaned = [t for t in tokens_exp if t not in tokens_flagged]\n",
    "#     tokens_cleaned = [t for t in tokens_cleaned if type(t) not in [sqlparse.sql.Comment]]\n",
    "    return tokens_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_from_with(subq_token):\n",
    "    for t in subq_token.tokens:\n",
    "        if isinstance(t,sqlparse.sql.Parenthesis):\n",
    "            return clean_query(t.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = '''--asd\n",
    "            with a as (select a_id1 as a_id, --abc\n",
    "            case when aa = \\'a1\\' and a2=3 then 1 else 0 end aa_ind --def\n",
    "            from `a123.aaa`) --pqr\n",
    "        , b as (select b_id, \n",
    "            sum(bb) bb_sum \n",
    "            from `b123.bbb` \n",
    "            group by b_id) \n",
    "        select a.a_id,a.a_ind,b.b_sum \n",
    "        from a left join b \n",
    "        on a.a_id = b.b_id'''\n",
    "\n",
    "query2 = '''select a.a_id,a.a_ind,b.b_sum \n",
    "        from a left join b \n",
    "        on a.a_id = b.b_id'''\n",
    "query3 = '''\n",
    "        select a.a_id, --aaa\n",
    "        max(a.a_ind) a_max,\n",
    "        sum(b.b_ind) b_sum\n",
    "        from a left join b \n",
    "        on a.a_id = b.b_id\n",
    "        where a.a_id != 0\n",
    "        group by 1\n",
    "        '''\n",
    "query4 = '''select a,b from aa'''\n",
    "query5 = '''select a,b from (select aa a,bb b from c)'''\n",
    "query6 = '''select a_id1 as a_id, --abc\n",
    "            case when aa = \\'a1\\' and a2=3 then 1 else 0 end aa_ind --def\n",
    "            from `a123.aaa`'''\n",
    "\n",
    "query7 = '''select b_id, \n",
    "            sum(bb) bb_sum \n",
    "            from `b123.bbb` \n",
    "            group by b_id'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_keywords = ['select','from','where','group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_c[0].ttype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_c = clean_query(sqlparse.parse(query3)[0].tokens)\n",
    "# q_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, False, False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_token_is_base_keyword(t,kw):\n",
    "    if kw == 'select':\n",
    "        return t.match(sqlparse.tokens.Keyword.DML,[kw])\n",
    "    else:\n",
    "        return t.match(sqlparse.tokens.Keyword,[kw])\n",
    "    \n",
    "# q_c[0].match(sqlparse.tokens.Keyword.DML,['select']),\\\n",
    "# q_c[2].match(sqlparse.tokens.Keyword,['from']),\\\n",
    "# isinstance(q_c[8],sqlparse.sql.Where),\\\n",
    "# q_c[9].match(sqlparse.tokens.Keyword,['group'])\n",
    "\n",
    "check_token_is_base_keyword(q_c[0],'select'),\\\n",
    "check_token_is_base_keyword(q_c[2],'from'),\\\n",
    "check_token_is_base_keyword(q_c[8],'where'),\\\n",
    "check_token_is_base_keyword(q_c[10],'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col_def(c,n):\n",
    "    return re.sub(n+'$','',c.split('--')[0].strip()).strip()\n",
    "    \n",
    "    \n",
    "# def parse_select_statement(s_tokens):\n",
    "#     op_dict = {}\n",
    "#     for t in s_tokens:\n",
    "#         if isinstance(t,sqlparse.sql.Identifier):\n",
    "#             op_dict[t.get_name()] = clean_col_def(t.value,t.get_alias())\n",
    "#         if isinstance(t,sqlparse.sql.IdentifierList):\n",
    "#             for tt in clean_query(t.tokens):\n",
    "#                 op_dict[tt.get_name()] = clean_col_def(tt.value,tt.get_alias())\n",
    "#     return op_dict\n",
    "\n",
    "def parse_select_statement(s_tokens):\n",
    "    op_dict = {}\n",
    "    for t in s_tokens:\n",
    "        if isinstance(t,sqlparse.sql.Identifier):\n",
    "            if isinstance(clean_query(t.tokens)[0],sqlparse.sql.Case):\n",
    "                op_dict[t.get_name()] = clean_col_def(t.value,t.get_name())\n",
    "#                 print(t.value,t.get_name(),clean_col_def(t.value,t.get_name()))\n",
    "            else:\n",
    "                op_dict[t.get_name()] = t.get_real_name()\n",
    "        elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "            for tt in clean_query(t.tokens):\n",
    "                op_dict[tt.get_name()] = tt.get_real_name()\n",
    "    return op_dict\n",
    "# def parse_\n",
    "\n",
    "def parse_from_statement(f_tolens):\n",
    "    op_dict = {}\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_simple_select(q_tokens):\n",
    "    assert check_token_is_base_keyword(q_tokens[0],'select')\n",
    "    \n",
    "    # initial high level parsing\n",
    "    q_parse_dict_1 = {kw:[] for kw in base_keywords}\n",
    "    base_keyword_idx = 0\n",
    "    for t in q_tokens:\n",
    "        is_kw_flag = False\n",
    "        for kw in base_keywords:\n",
    "            if check_token_is_base_keyword(t,kw):\n",
    "                key = kw\n",
    "                is_kw_flag = True\n",
    "#         if check_token_is_base_keyword(t,base_keywords[base_keyword_idx]):\n",
    "#             key = base_keywords[base_keyword_idx]\n",
    "#             q_parse_dict_1[key] = []\n",
    "#             if base_keyword_idx<len(base_keywords)-1:\n",
    "#                 base_keyword_idx+=1\n",
    "#             continue\n",
    "        if not is_kw_flag:\n",
    "            q_parse_dict_1[key].append(t)\n",
    "    q_parse_dict_1['select'] = parse_select_statement(q_parse_dict_1['select'])\n",
    "    return q_parse_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': {'a_id': 'a_id', 'a_max': 'max', 'b_sum': 'sum'},\n",
       " 'from': [<Identifier 'a' at 0x29721B210C0>,\n",
       "  <Keyword 'left j...' at 0x29721B1A4C8>,\n",
       "  <Identifier 'b' at 0x29721B21138>,\n",
       "  <Keyword 'on' at 0x29721B1A648>,\n",
       "  <Comparison 'a.a_id...' at 0x29721B211B0>],\n",
       " 'where': [<Comparison 'a.a_id...' at 0x29721B21228>],\n",
       " 'group': [<Keyword 'by' at 0x29721B1B048>, <Integer '1' at 0x29721B1B108>]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_simple_select(q_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_select_q(q):\n",
    "    parsed_q = sqlparse.parse(q)[0] # assumed that q has a single query\n",
    "    q_tokens = parsed_q.tokens\n",
    "    q_tokens_c = clean_query(q_tokens)\n",
    "    \n",
    "    if q_tokens_c[0].match(sqlparse.tokens.Keyword.CTE,['with']):\n",
    "        # do something about query with with\n",
    "        print('with')\n",
    "        \n",
    "        # list,dict of all subqueries\n",
    "        subq_list_raw = clean_query(q_tokens_c[1].tokens)\n",
    "        subq_dict = {subq.get_name():parse_simple_select(get_select_from_with(subq)) for subq in subq_list_raw}\n",
    "#         subq_list_c = subq_dict.values()\n",
    "        \n",
    "        # parse individual subqueries\n",
    "#         print(subq_dict)\n",
    "        # for q in subq_dict, parse_simple_select\n",
    "        \n",
    "        if q_tokens_c[2].match(sqlparse.tokens.Keyword.DML,['select']):\n",
    "            overall_select_parsed = parse_simple_select(q_tokens_c[2:])\n",
    "        overall_select_parsed['subqueries'] = subq_dict\n",
    "        \n",
    "    elif q_tokens_c[0].match(sqlparse.tokens.Keyword.DML,['select']):\n",
    "        # simpler query, parse it\n",
    "        print('select')\n",
    "        overall_select_parsed = parse_simple_select(q_tokens_c)\n",
    "    else:\n",
    "        print(q_tokens_c)\n",
    "        raise Exception('wut')\n",
    "        \n",
    "    return overall_select_parsed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select b_id, \n",
      "            sum(bb) bb_sum \n",
      "            from `b123.bbb` \n",
      "            group by b_id\n"
     ]
    }
   ],
   "source": [
    "print(query7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected text or file-like object, got <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a05b4b5d92ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparse_select_q\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-28d336cd3d85>\u001b[0m in \u001b[0;36mparse_select_q\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# list,dict of all subqueries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msubq_list_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_tokens_c\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msubq_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msubq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mparse_select_q\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_select_from_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubq_list_raw\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#         subq_list_c = subq_dict.values()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-28d336cd3d85>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# list,dict of all subqueries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msubq_list_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_tokens_c\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msubq_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msubq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mparse_select_q\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_select_from_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubq_list_raw\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#         subq_list_c = subq_dict.values()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-28d336cd3d85>\u001b[0m in \u001b[0;36mparse_select_q\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_select_q\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mparsed_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# assumed that q has a single query\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mq_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mq_tokens_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlparse\\__init__.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(sql, encoding)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0msqlparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatement\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsestream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlparse\\engine\\filter_stack.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, sql, encoding)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Output: Stream processed Statements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mstmt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grouping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mstmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlparse\\engine\\statement_splitter.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m# Run over all stream tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mttype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;31m# Yield token if we finished a statement and there's no whitespaces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;31m# It will count newline token as a non whitespace. In this context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlparse\\lexer.py\u001b[0m in \u001b[0;36mget_tokens\u001b[1;34m(text, encoding)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             raise TypeError(u\"Expected text or file-like object, got {!r}\".\n\u001b[1;32m---> 55\u001b[1;33m                             format(type(text)))\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0miterable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected text or file-like object, got <class 'list'>"
     ]
    }
   ],
   "source": [
    "parse_select_q(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"case when aa = 'a1' and a2=3 then 1 else 0 end\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_col_def(\"case when aa = 'a1' and a2=3 then 1 else 0 end aa_ind\",\"aa_ind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_token_is_base_keyword(clean_query(sqlparse.parse(query7)[0].tokens)[4],'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
