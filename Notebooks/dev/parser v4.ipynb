{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "from sqlparse.sql import Token, TokenList\n",
    "import re\n",
    "import json\n",
    "import random, string\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_keywords = ['select','from','where','group','having']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_query(tokens):\n",
    "    tokens_exp = []\n",
    "    tokens_cleaned = []\n",
    "    for t in tokens:\n",
    "        if isinstance(t,sqlparse.sql.Where):\n",
    "            for tt in t.tokens:\n",
    "                tokens_exp.append(tt)\n",
    "        else:\n",
    "            tokens_exp.append(t)\n",
    "            \n",
    "#     print(tokens_exp)\n",
    "    \n",
    "    for t in tokens_exp:\n",
    "        append_flag = True\n",
    "        for pattern in ['Token.Text.Whitespace*','Token.Punctuation*']:\n",
    "            if re.match(pattern,str(t.ttype)):\n",
    "                append_flag = False\n",
    "        for t_type in [sqlparse.sql.Comment]:\n",
    "            if type(t)==t_type:\n",
    "                append_flag = False\n",
    "                \n",
    "        if append_flag:\n",
    "            tokens_cleaned.append(t)\n",
    "                \n",
    "#     tokens_cleaned = [t for t in tokens_exp if t not in tokens_flagged]\n",
    "#     tokens_cleaned = [t for t in tokens_cleaned if type(t) not in [sqlparse.sql.Comment]]\n",
    "    return tokens_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_select_from_with(subq_token):\n",
    "    for t in subq_token.tokens:\n",
    "        if isinstance(t,sqlparse.sql.Parenthesis):\n",
    "            return clean_query(t.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_token_is_base_keyword(t,kw):\n",
    "    if kw == 'select':\n",
    "        return t.match(sqlparse.tokens.Keyword.DML,['select'])\n",
    "    else:\n",
    "        return t.match(sqlparse.tokens.Keyword,[kw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_simple_select(q_tokens):\n",
    "    assert check_token_is_base_keyword(q_tokens[0],'select')\n",
    "    \n",
    "    # initial high level parsing\n",
    "    q_parse_dict_1 = {kw:[] for kw in base_keywords}\n",
    "    base_keyword_idx = 0\n",
    "    for t in q_tokens:\n",
    "        is_kw_flag = False\n",
    "        for kw in base_keywords:\n",
    "            if check_token_is_base_keyword(t,kw):\n",
    "                key = kw\n",
    "                is_kw_flag = True\n",
    "#         if check_token_is_base_keyword(t,base_keywords[base_keyword_idx]):\n",
    "#             key = base_keywords[base_keyword_idx]\n",
    "#             q_parse_dict_1[key] = []\n",
    "#             if base_keyword_idx<len(base_keywords)-1:\n",
    "#                 base_keyword_idx+=1\n",
    "#             continue\n",
    "        if not is_kw_flag:\n",
    "            q_parse_dict_1[key].append(t)\n",
    "    \n",
    "    return q_parse_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col_def(c,n):\n",
    "    return re.sub('\\ '+n+'$','',c.split('--')[0].strip()).strip()\n",
    "    \n",
    "def parse_select_statement(s_tokens):\n",
    "    op_dict = {}\n",
    "    for t in s_tokens:\n",
    "        if isinstance(t,sqlparse.sql.Identifier):\n",
    "            if isinstance(clean_query(t.tokens)[0],sqlparse.sql.Case):\n",
    "                op_dict[t.get_name()] = clean_col_def(t.value,t.get_name())\n",
    "#                 print(t.value,t.get_name(),clean_col_def(t.value,t.get_name()))\n",
    "            else:\n",
    "#                 op_dict[t.get_name()] = t.get_real_name()\n",
    "                op_dict[t.get_name()] = clean_col_def(t.value,t.get_name())\n",
    "        elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "            for tt in clean_query(t.tokens):\n",
    "#                 op_dict[tt.get_name()] = tt.get_real_name()\n",
    "                op_dict[tt.get_name()] = clean_col_def(tt.value,tt.get_name())\n",
    "    return op_dict\n",
    "\n",
    "\n",
    "def parse_from_statement(f_tokens):\n",
    "    op_dict = {'input_tables':{}}\n",
    "        \n",
    "    # only identifier or identifier list present in f_tokens\n",
    "    only_identifiers_flag=True\n",
    "    for t in f_tokens:\n",
    "        if not (isinstance(t,sqlparse.sql.Identifier) or isinstance(t,sqlparse.sql.IdentifierList)):\n",
    "            only_identifiers_flag=False\n",
    "    \n",
    "    if only_identifiers_flag:\n",
    "        for t in f_tokens:\n",
    "            if isinstance(t,sqlparse.sql.Identifier):\n",
    "                op_dict['input_tables'][t.get_name()] = t.get_real_name()\n",
    "            elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "                for tt in clean_query(t.tokens):\n",
    "                    op_dict['input_tables'][tt.get_name()] = tt.get_real_name()\n",
    "        return op_dict\n",
    "    \n",
    "    # join statement\n",
    "    op_dict['joins'] = {}\n",
    "    for i,t in enumerate(f_tokens):\n",
    "        if isinstance(t,sqlparse.sql.Identifier):\n",
    "            op_dict['input_tables'][t.get_name()] = t.get_real_name()\n",
    "            \n",
    "        if check_token_is_base_keyword(t,'left join') \\\n",
    "        or check_token_is_base_keyword(t,'right join') \\\n",
    "        or check_token_is_base_keyword(t,'inner join') \\\n",
    "        or check_token_is_base_keyword(t,'join') \\\n",
    "        or check_token_is_base_keyword(t,'full outer join'):\n",
    "            key = f_tokens[i+1].get_name()\n",
    "            join_dict = {}\n",
    "            join_dict['type'] = t.value.replace(' join','')\n",
    "            if join_dict['type']=='join':\n",
    "                join_dict['type'] = 'inner'\n",
    "            join_dict['on'] = f_tokens[i+3].value\n",
    "            op_dict['joins'][key] = join_dict\n",
    "    \n",
    "    return op_dict        \n",
    "            \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sel_from_q = '''\n",
    "        select a.a_id, --aaa\n",
    "        max(a.a_ind) a_max,\n",
    "        sum(b.b_ind) b_sum\n",
    "        from a left join b \n",
    "        on a.a_id = b.b_id\n",
    "        right join c\n",
    "        on a.a_id = c.c_id\n",
    "        where a.a_id != 0\n",
    "        group by 1\n",
    "        '''\n",
    "\n",
    "test_sel_from_q_2 = '''\n",
    "        select a.a_id, --aaa\n",
    "        max(a.a_ind) a_max,\n",
    "        sum(b.b_ind) b_sum\n",
    "        from asd a, basd b \n",
    "        where a.a_id = b.b_id\n",
    "        and a.a_id != 0\n",
    "        group by 1\n",
    "        '''\n",
    "\n",
    "\n",
    "test_sel_from_q_3 = '''\n",
    "        select a.a_id, --aaa\n",
    "        max(a.a_ind) a_max,\n",
    "        sum(b.b_ind) b_sum\n",
    "        from a,\n",
    "        (select * from basd) b \n",
    "        where a.a_id = b.b_id\n",
    "        and a.a_id != 0\n",
    "        group by 1\n",
    "        '''\n",
    "\n",
    "test_sel_from_q_4 = '''\n",
    "        select a.a_id, --aaa\n",
    "        max(a.a_ind) a_max,\n",
    "        sum(b.b_ind) b_sum\n",
    "        from asd a,\n",
    "        (select * from basd) b \n",
    "        where a.a_id = b.b_id\n",
    "        and a.a_id != 0\n",
    "        group by 1\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_c = clean_query(sqlparse.parse(test_sel_from_q)[0].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'select' at 0x2B983CF96A8>,\n",
       " <Identifier 'a.a_id' at 0x2B983CF1C78>,\n",
       " <IdentifierList 'max(a....' at 0x2B983D199A8>,\n",
       " <Keyword 'from' at 0x2B983D18468>,\n",
       " <Identifier 'a' at 0x2B983D195E8>,\n",
       " <Keyword 'left j...' at 0x2B983D185E8>,\n",
       " <Identifier 'b' at 0x2B983D19660>,\n",
       " <Keyword 'on' at 0x2B983D18768>,\n",
       " <Comparison 'a.a_id...' at 0x2B983D19750>,\n",
       " <Keyword 'right ...' at 0x2B983D18C48>,\n",
       " <Identifier 'c' at 0x2B983D196D8>,\n",
       " <Keyword 'on' at 0x2B983D18E28>,\n",
       " <Comparison 'a.a_id...' at 0x2B983D197C8>,\n",
       " <Keyword 'where' at 0x2B983D3E348>,\n",
       " <Comparison 'a.a_id...' at 0x2B983D19840>,\n",
       " <Keyword 'group' at 0x2B983D3E768>,\n",
       " <Keyword 'by' at 0x2B983D3E828>,\n",
       " <Integer '1' at 0x2B983D3E8E8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_c_p = parse_simple_select(q_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'select': [<Identifier 'a.a_id' at 0x2B983CF1C78>,\n",
       "  <IdentifierList 'max(a....' at 0x2B983D199A8>],\n",
       " 'from': [<Identifier 'a' at 0x2B983D195E8>,\n",
       "  <Keyword 'left j...' at 0x2B983D185E8>,\n",
       "  <Identifier 'b' at 0x2B983D19660>,\n",
       "  <Keyword 'on' at 0x2B983D18768>,\n",
       "  <Comparison 'a.a_id...' at 0x2B983D19750>,\n",
       "  <Keyword 'right ...' at 0x2B983D18C48>,\n",
       "  <Identifier 'c' at 0x2B983D196D8>,\n",
       "  <Keyword 'on' at 0x2B983D18E28>,\n",
       "  <Comparison 'a.a_id...' at 0x2B983D197C8>],\n",
       " 'where': [<Comparison 'a.a_id...' at 0x2B983D19840>],\n",
       " 'group': [<Keyword 'by' at 0x2B983D3E828>, <Integer '1' at 0x2B983D3E8E8>],\n",
       " 'having': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_c_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_id': 'a.a_id', 'a_max': 'max(a.a_ind)', 'b_sum': 'sum(b.b_ind)'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_select_statement(q_c_p['select'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_query(clean_query(q_c_p['from'][0].tokens)[0].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Identifier 'a' at 0x2B983D195E8>,\n",
       " <Keyword 'left j...' at 0x2B983D185E8>,\n",
       " <Identifier 'b' at 0x2B983D19660>,\n",
       " <Keyword 'on' at 0x2B983D18768>,\n",
       " <Comparison 'a.a_id...' at 0x2B983D19750>,\n",
       " <Keyword 'right ...' at 0x2B983D18C48>,\n",
       " <Identifier 'c' at 0x2B983D196D8>,\n",
       " <Keyword 'on' at 0x2B983D18E28>,\n",
       " <Comparison 'a.a_id...' at 0x2B983D197C8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_w_par = q_c_p['from']\n",
    "from_w_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_token_is_base_keyword(from_w_par[1],'left join')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplq_dict = {}\n",
    "# for t in from_w_par:\n",
    "#     if isinstance(t,sqlparse.sql.Identifier):\n",
    "#         subsel = get_select_from_with(t)\n",
    "#         if subsel:\n",
    "#             simplq_dict[t.get_name()] = subsel\n",
    "#             replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Name 'a' at 0x2B983D18528>,\n",
       " <Keyword 'left j...' at 0x2B983D185E8>,\n",
       " <Name 'b' at 0x2B983D186A8>,\n",
       " <Keyword 'on' at 0x2B983D18768>,\n",
       " <Name 'a' at 0x2B983D18828>,\n",
       " <Punctuation '.' at 0x2B983D18888>,\n",
       " <Name 'a_id' at 0x2B983D188E8>,\n",
       " <Whitespace ' ' at 0x2B983D18948>,\n",
       " <Comparison '=' at 0x2B983D189A8>,\n",
       " <Whitespace ' ' at 0x2B983D18A08>,\n",
       " <Name 'b' at 0x2B983D18A68>,\n",
       " <Punctuation '.' at 0x2B983D18AC8>,\n",
       " <Name 'b_id' at 0x2B983D18B28>,\n",
       " <Keyword 'right ...' at 0x2B983D18C48>,\n",
       " <Name 'c' at 0x2B983D18D08>,\n",
       " <Keyword 'on' at 0x2B983D18E28>,\n",
       " <Name 'a' at 0x2B983D18EE8>,\n",
       " <Punctuation '.' at 0x2B983D18F48>,\n",
       " <Name 'a_id' at 0x2B983D18FA8>,\n",
       " <Whitespace ' ' at 0x2B983D3E048>,\n",
       " <Comparison '=' at 0x2B983D3E0A8>,\n",
       " <Whitespace ' ' at 0x2B983D3E108>,\n",
       " <Name 'c' at 0x2B983D3E168>,\n",
       " <Punctuation '.' at 0x2B983D3E1C8>,\n",
       " <Name 'c_id' at 0x2B983D3E228>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l = []\n",
    "for t in q_c_p['from']:\n",
    "    test_l.extend(list(t.flatten()))\n",
    "test_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not max([check_token_is_base_keyword(t,'select') for t in test_l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tables': {'a': 'a', 'b': 'b', 'c': 'c'},\n",
       " 'joins': {'b': {'type': 'left', 'on': 'a.a_id = b.b_id'},\n",
       "  'c': {'type': 'right', 'on': 'a.a_id = c.c_id'}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_from_statement(q_c_p['from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(l=8):\n",
    "    x = ''.join(random.choices(string.ascii_letters + string.digits, k=l))\n",
    "    return x\n",
    "\n",
    "def get_all_queries(q_tokens_c):\n",
    "    all_queries={}\n",
    "    \n",
    "    if q_tokens_c[0].match(sqlparse.tokens.Keyword.CTE,['with']):\n",
    "        # get all subqueries from with\n",
    "\n",
    "        # list,dict of all subqueries\n",
    "        subq_list_raw = clean_query(q_tokens_c[1].tokens)\n",
    "        all_queries.update({subq.get_name(): parse_simple_select(get_select_from_with(subq)) for subq in subq_list_raw})\n",
    "\n",
    "        if q_tokens_c[2].match(sqlparse.tokens.Keyword.DML,['select']):\n",
    "            all_queries['out'] = parse_simple_select(q_tokens_c[2:])\n",
    " \n",
    "    elif q_tokens_c[0].match(sqlparse.tokens.Keyword.DML,['select']):\n",
    "        # simpler query, parse it\n",
    "        all_queries['out'] = parse_simple_select(q_tokens_c)\n",
    "        \n",
    "    return all_queries\n",
    "\n",
    "def is_simple_select(parsed_t_s):\n",
    "    from_t = []\n",
    "    for t in parsed_t_s['from']:\n",
    "        from_t.extend(list(t.flatten()))\n",
    "    return not max([check_token_is_base_keyword(t,'select') for t in from_t])\n",
    "\n",
    "def make_simple(parsed_t_s, init_parsed):\n",
    "    if is_simple_select(parsed_t_s):\n",
    "        parsed_t_s['from'] = parse_from_statement(parsed_t_s['from'])\n",
    "        return parsed_t_s\n",
    "    else:\n",
    "        new_from = parse_from_statement(parsed_t_s['from'])\n",
    "        for i in range(len(parsed_t_s['from'])):\n",
    "            t = parsed_t_s['from'][i]\n",
    "            if isinstance(t,sqlparse.sql.Identifier):\n",
    "                # asdasd\n",
    "                sel = parse_simple_select(get_select_from_with(t))\n",
    "                if sel:\n",
    "                    subq_name = generate_name()\n",
    "                    new_from['input_tables'][t.get_name()] = subq_name\n",
    "                    init_parsed[subq_name] = make_simple(sel,init_parsed)\n",
    "            elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "                for tt in clean_query(t.tokens):\n",
    "                    sel = parse_simple_select(get_select_from_with(tt))\n",
    "                    if sel:\n",
    "                        subq_name = generate_name()\n",
    "                        new_from['input_tables'][tt.get_name()] = subq_name\n",
    "                        init_parsed[subq_name] = make_simple(sel,init_parsed)\n",
    "        parsed_t_s['from'] = new_from\n",
    "        return parsed_t_s\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subq_test_q_1 = '''--asd\n",
    "            with a as (select a_id1 as a_id, --abc\n",
    "            case when aa = \\'a1\\' and a2=3 then 1 else 0 end aa_ind --def\n",
    "            from (select q.* from `a123.aaa` q) abc) --pqr\n",
    "        , b as (select b_id, \n",
    "            sum(bb) bb_sum \n",
    "            from `b123.bbb` \n",
    "            group by b_id\n",
    "            having sum(bb)>2) \n",
    "        select a.a_id,a.a_ind,b.b_sum \n",
    "        from a left join b \n",
    "        on a.a_id = b.b_id'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_q = sqlparse.parse(subq_test_q_1)[0] # assumed that q has a single query\n",
    "q_tokens = parsed_q.tokens\n",
    "q_tokens_c = clean_query(q_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "global all_queries\n",
    "all_queries = get_all_queries(q_tokens_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'select': [<Identifier 'a_id1 ...' at 0x2B983D606D8>,\n",
       "   <Identifier 'case w...' at 0x2B983D46570>],\n",
       "  'from': [<Identifier '(selec...' at 0x2B983D465E8>],\n",
       "  'where': [],\n",
       "  'group': [],\n",
       "  'having': []},\n",
       " 'b': {'select': [<IdentifierList 'b_id, ...' at 0x2B983D46660>],\n",
       "  'from': [<Identifier '`b123....' at 0x2B983D460C0>],\n",
       "  'where': [],\n",
       "  'group': [<Keyword 'by' at 0x2B983D501C8>,\n",
       "   <Identifier 'b_id' at 0x2B983D46138>],\n",
       "  'having': [<Comparison 'sum(bb...' at 0x2B983D46408>]},\n",
       " 'out': {'select': [<IdentifierList 'a.a_id...' at 0x2B983D46750>],\n",
       "  'from': [<Identifier 'a' at 0x2B983D46228>,\n",
       "   <Keyword 'left j...' at 0x2B983D50E28>,\n",
       "   <Identifier 'b' at 0x2B983D462A0>,\n",
       "   <Keyword 'on' at 0x2B983D50FA8>,\n",
       "   <Comparison 'a.a_id...' at 0x2B983D46480>],\n",
       "  'where': [],\n",
       "  'group': [],\n",
       "  'having': []}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = copy.deepcopy(list(all_queries.keys()))\n",
    "for k in ks:\n",
    "    all_queries[k] = make_simple(all_queries[k],all_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'select': [<Identifier 'a_id1 ...' at 0x2B983D606D8>,\n",
       "   <Identifier 'case w...' at 0x2B983D46570>],\n",
       "  'from': {'input_tables': {'abc': 'kQ6PfV7Q'}},\n",
       "  'where': [],\n",
       "  'group': [],\n",
       "  'having': []},\n",
       " 'b': {'select': [<IdentifierList 'b_id, ...' at 0x2B983D46660>],\n",
       "  'from': {'input_tables': {'`b123.bbb`': '`b123.bbb`'}},\n",
       "  'where': [],\n",
       "  'group': [<Keyword 'by' at 0x2B983D501C8>,\n",
       "   <Identifier 'b_id' at 0x2B983D46138>],\n",
       "  'having': [<Comparison 'sum(bb...' at 0x2B983D46408>]},\n",
       " 'out': {'select': [<IdentifierList 'a.a_id...' at 0x2B983D46750>],\n",
       "  'from': {'input_tables': {'a': 'a', 'b': 'b'},\n",
       "   'joins': {'b': {'type': 'left', 'on': 'a.a_id = b.b_id'}}},\n",
       "  'where': [],\n",
       "  'group': [],\n",
       "  'having': []},\n",
       " 'kQ6PfV7Q': {'select': [<Identifier 'q.*' at 0x2B983D60570>],\n",
       "  'from': {'input_tables': {'q': '`a123.aaa`'}},\n",
       "  'where': [],\n",
       "  'group': [],\n",
       "  'having': []}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'si2CjupY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1cf6cb354749>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_queries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'si2CjupY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'select'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_wildcard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'si2CjupY'"
     ]
    }
   ],
   "source": [
    "all_queries['si2CjupY']['select'][0].is_wildcard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries['si2CjupY']['select'][0].match(sqlparse.tokens.Wildcard,'q.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple select query: Select query with no subquery\n",
    "\"\"\"\n",
    "\n",
    "class SelectQuery():\n",
    "    def __init__(self,query_text):\n",
    "        self.query_text = query_text\n",
    "        self.simple_select_queries = {}\n",
    "        self.keywords = ['select','from','where','group','having']\n",
    "    \n",
    "    def parse_select_query(self):\n",
    "        self.init_parse_query()\n",
    "        \n",
    "        # get all initial select queries\n",
    "        self.get_all_queries()\n",
    "#         print(self.all_queries)\n",
    "        # convert all queries to simple queries\n",
    "        ks = copy.deepcopy(list(self.all_queries.keys()))\n",
    "        for k in ks:\n",
    "            self.all_queries[k] = self.make_simple(self.all_queries[k])\n",
    "#         print(self.all_queries)\n",
    "        # parse statements\n",
    "        ks = copy.deepcopy(list(self.all_queries.keys()))\n",
    "        for k in ks:\n",
    "            # select\n",
    "            self.all_queries[k]['select'] = self.parse_select_statement(self.all_queries[k]['select'])\n",
    "            # where\n",
    "            # group\n",
    "            # having\n",
    "        \n",
    "    \n",
    "    def init_parse_query(self):\n",
    "        parsed_q = sqlparse.parse(self.query_text)[0] # assumed that q has a single query\n",
    "        q_tokens = parsed_q.tokens\n",
    "        q_tokens_c = self._clean_query(q_tokens)\n",
    "        self.init_parse = q_tokens_c\n",
    "\n",
    "    def get_all_queries(self):\n",
    "        all_queries={}\n",
    "        \n",
    "        if self.init_parse[0].match(sqlparse.tokens.Keyword.CTE,['with']):\n",
    "            # get all subqueries from with\n",
    "\n",
    "            # list,dict of all subqueries\n",
    "            subq_list_raw = self._clean_query(self.init_parse[1].tokens)\n",
    "            all_queries.update({subq.get_name(): self.parse_simple_select(self._get_select_from_par(subq)) for subq in subq_list_raw})\n",
    "\n",
    "            if self.init_parse[2].match(sqlparse.tokens.Keyword.DML,['select']):\n",
    "                all_queries['out'] = self.parse_simple_select(self.init_parse[2:])\n",
    "\n",
    "        elif self.init_parse[0].match(sqlparse.tokens.Keyword.DML,['select']):\n",
    "            # simpler query, parse it\n",
    "            all_queries['out'] = self.parse_simple_select(self.init_parse)\n",
    "\n",
    "        self.all_queries = all_queries\n",
    "    \n",
    "    def parse_simple_select(self,q_tokens):\n",
    "        assert self._check_token_is_base_keyword(q_tokens[0],'select')\n",
    "\n",
    "        # initial high level parsing\n",
    "        q_parse_dict_1 = {kw:[] for kw in self.keywords}\n",
    "        base_keyword_idx = 0\n",
    "        for t in q_tokens:\n",
    "            is_kw_flag = False\n",
    "            for kw in base_keywords:\n",
    "                if self._check_token_is_base_keyword(t,kw):\n",
    "                    key = kw\n",
    "                    is_kw_flag = True\n",
    "            if not is_kw_flag:\n",
    "                q_parse_dict_1[key].append(t)\n",
    "\n",
    "        return q_parse_dict_1\n",
    "    \n",
    "    def make_simple(self,parsed_t_s):\n",
    "        if self._is_simple_select(parsed_t_s):\n",
    "            parsed_t_s['from'] = self.parse_from_statement(parsed_t_s['from'])\n",
    "            return parsed_t_s\n",
    "        else:\n",
    "            new_from = self.parse_from_statement(parsed_t_s['from'])\n",
    "            for i in range(len(parsed_t_s['from'])):\n",
    "                t = parsed_t_s['from'][i]\n",
    "                if isinstance(t,sqlparse.sql.Identifier):\n",
    "                    sel = self.parse_simple_select(self._get_select_from_par(t))\n",
    "                    if sel:\n",
    "                        subq_name = self._generate_name()\n",
    "                        new_from['input_tables'][t.get_name()] = subq_name\n",
    "                        self.all_queries[subq_name] = self.make_simple(sel)\n",
    "                elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "                    for tt in self._clean_query(t.tokens):\n",
    "                        sel = self.parse_simple_select(self._get_select_from_par(tt))\n",
    "                        if sel:\n",
    "                            subq_name = self._generate_name()\n",
    "                            new_from['input_tables'][tt.get_name()] = subq_name\n",
    "                            self.all_queries[subq_name] = self.make_simple(sel)\n",
    "            parsed_t_s['from'] = new_from\n",
    "            return parsed_t_s              \n",
    "    \n",
    "    \n",
    "    def parse_select_statement(self,s_tokens):\n",
    "        op_dict = {}\n",
    "        for t in s_tokens:\n",
    "            if isinstance(t,sqlparse.sql.Identifier):\n",
    "                if isinstance(self._clean_query(t.tokens)[0],sqlparse.sql.Case):\n",
    "                    op_dict[t.get_name()] = self._clean_col_def(t.value,t.get_name())\n",
    "                else:\n",
    "                    op_dict[t.get_name()] = self._clean_col_def(t.value,t.get_name())\n",
    "            elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "                for tt in self._clean_query(t.tokens):\n",
    "                    op_dict[tt.get_name()] = self._clean_col_def(tt.value,tt.get_name())\n",
    "        return op_dict\n",
    "\n",
    "\n",
    "    def parse_from_statement(self,f_tokens):\n",
    "        op_dict = {'input_tables':{}}\n",
    "\n",
    "        # only identifier or identifier list present in f_tokens\n",
    "        only_identifiers_flag=True\n",
    "        for t in f_tokens:\n",
    "            if not (isinstance(t,sqlparse.sql.Identifier) or isinstance(t,sqlparse.sql.IdentifierList)):\n",
    "                only_identifiers_flag=False\n",
    "\n",
    "        if only_identifiers_flag:\n",
    "            for t in f_tokens:\n",
    "                if isinstance(t,sqlparse.sql.Identifier):\n",
    "                    op_dict['input_tables'][t.get_name()] = t.get_real_name()\n",
    "                elif isinstance(t,sqlparse.sql.IdentifierList):\n",
    "                    for tt in self._clean_query(t.tokens):\n",
    "                        op_dict['input_tables'][tt.get_name()] = tt.get_real_name()\n",
    "            return op_dict\n",
    "\n",
    "        # join statement\n",
    "        op_dict['joins'] = {}\n",
    "        for i,t in enumerate(f_tokens):\n",
    "            if isinstance(t,sqlparse.sql.Identifier):\n",
    "                op_dict['input_tables'][t.get_name()] = t.get_real_name()\n",
    "\n",
    "            if self._check_token_is_base_keyword(t,['left join','right join','inner join','join','full outer join']):\n",
    "                key = f_tokens[i+1].get_name()\n",
    "                join_dict = {}\n",
    "                join_dict['type'] = t.value.replace(' join','')\n",
    "                if join_dict['type']=='join':\n",
    "                    join_dict['type'] = 'inner'\n",
    "                join_dict['on'] = f_tokens[i+3].value\n",
    "                op_dict['joins'][key] = join_dict\n",
    "\n",
    "        return op_dict        \n",
    "\n",
    "\n",
    "\n",
    "    # helper functions\n",
    "    def _clean_col_def(self,c,n):\n",
    "        return re.sub('\\ '+n+'$','',c.split('--')[0].strip()).strip()\n",
    "\n",
    "    def _generate_name(self,l=8):\n",
    "        x = ''.join(random.choices(string.ascii_letters + string.digits, k=l))\n",
    "        return x\n",
    " \n",
    "    def _is_simple_select(self,q_t):\n",
    "        from_t = []\n",
    "        for t in q_t['from']:\n",
    "            from_t.extend(list(t.flatten()))\n",
    "        return not max([self._check_token_is_base_keyword(t,'select') for t in from_t])\n",
    "        \n",
    "    def _check_token_is_base_keyword(self,t,kw):\n",
    "        if 'select' in kw:\n",
    "            return t.match(sqlparse.tokens.Keyword.DML,kw)\n",
    "        else:\n",
    "            return t.match(sqlparse.tokens.Keyword,kw)\n",
    "\n",
    "    def _get_select_from_par(self,subq_token):\n",
    "        for t in subq_token.tokens:\n",
    "            if isinstance(t,sqlparse.sql.Parenthesis):\n",
    "                return self._clean_query(t.tokens)\n",
    "        \n",
    "    def _clean_query(self,tokens):\n",
    "        tokens_exp = []\n",
    "        tokens_cleaned = []\n",
    "        for t in tokens:\n",
    "            if isinstance(t,sqlparse.sql.Where):\n",
    "                for tt in t.tokens:\n",
    "                    tokens_exp.append(tt)\n",
    "            else:\n",
    "                tokens_exp.append(t)\n",
    "\n",
    "        for t in tokens_exp:\n",
    "            append_flag = True\n",
    "            for pattern in ['Token.Text.Whitespace*','Token.Punctuation*']:\n",
    "                if re.match(pattern,str(t.ttype)):\n",
    "                    append_flag = False\n",
    "            for t_type in [sqlparse.sql.Comment]:\n",
    "                if type(t)==t_type:\n",
    "                    append_flag = False\n",
    "\n",
    "            if append_flag:\n",
    "                tokens_cleaned.append(t)\n",
    "\n",
    "        return tokens_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_obj = SelectQuery(subq_test_q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_obj.parse_select_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_obj.all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'select' in 'select'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
